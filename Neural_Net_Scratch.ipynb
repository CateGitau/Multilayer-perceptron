{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a multi-layer perceptron with one hidden layer from scratch and test it on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigma(x):\n",
    "    return 1 - sigma(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(v, t):\n",
    "    return (v-t).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss(v, t):\n",
    "    return 2*(v-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "torch.Size([1000, 784])\n"
     ]
    }
   ],
   "source": [
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "train_input, train_target, test_input,test_target = prologue.load_data(one_hot_labels = True,\n",
    "                                                                      normalize = True)\n",
    "\n",
    "train_target = train_target * 0.9\n",
    "test_target  = test_target * 0.9\n",
    "print(train_input.shape)\n",
    "\n",
    "nb_hidden = 50\n",
    "epsilon = 1e-6\n",
    "nb_classes = train_target.size(1)\n",
    "nb_train_samples = train_input.size(0)\n",
    "learning_rate = 0.1\n",
    "step = learning_rate/nb_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.empty(nb_hidden, train_input.size(1)).normal_(0, epsilon)\n",
    "b1 = torch.empty(nb_hidden, train_input.size(0)).normal_(0, epsilon)\n",
    "w2 = torch.empty(nb_classes, nb_hidden).normal_(0, epsilon)\n",
    "b2 = torch.empty(nb_classes, train_input.size(0)).normal_(0, epsilon)\n",
    "\n",
    "\n",
    "dl_dw1 = torch.empty(w1.size())\n",
    "dl_db1 = torch.empty(b1.size())\n",
    "dl_dw2 = torch.empty(w2.size())\n",
    "dl_db2 = torch.empty(b2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(w1, w2, b1, b2, x):\n",
    "    s1 = torch.add(torch.mm(w1, torch.transpose(x, 0, 1)), b1)\n",
    "    x1 = sigma(s1)\n",
    "    s2 = torch.add(torch.mm(w2,x1), b2)\n",
    "    x2 = sigma(s1)\n",
    "    \n",
    "    return s1, x1, s2, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1000])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b1.shape\n",
    "#s1 = torch.add(torch.mm(w1, torch.transpose(x, 0, 1)), b1)\n",
    "#x1 = sigma(s1)\n",
    "\n",
    "#x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#forward_pass(w1, w2, b1, b2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                 dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    \n",
    "    dl_dx2 = loss(x2, t)\n",
    "    dl_ds2 = torch.mm(dl_dx2, dsigma)\n",
    "    dl_dx1 = torch.mm(dl_s2, w2)\n",
    "    dl_ds1 = torch.mm(dl_dx1, dsigma(s1))\n",
    "    \n",
    "    dl_dw2 = torch.mm(dl_ds2, x1)\n",
    "    dl_db2 = torch.mm(dl_ds2, 1)\n",
    "    dl_db1 = torch.mm(dl_ds1, 1)\n",
    "    dl_dw1 = torch.mm(dl_ds1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-176794494ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#backward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-08964917d3ff>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(w1, w2, b1, b2, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "for k in range(1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performing 1,000 gradient steps with a step size equal to 0.1 divided\n",
    "    by the number of training samples(variable--steps)\n",
    "    First reset the tensors to zero for summing up the gradients and doing\n",
    "    a forward and backward pass for each training example\n",
    "    \"\"\"\n",
    "    dl_dw1 = torch.zeros(dl_dw1.shape)\n",
    "    dl_db1 = torch.zeros(dl_db1.shape)\n",
    "    dl_dw2 = torch.zeros(dl_dw2.shape)\n",
    "    dl_db2 = torch.zeros(dl_db2.shape)\n",
    "    \n",
    "    for n in range(nb_train_samples):\n",
    "        #forward prop\n",
    "        \n",
    "        x, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, train_input[n])\n",
    "    \n",
    "        #backward prop\n",
    "        backward_pass(w1, b1, w2, b2,\n",
    "                     train_input[n],\n",
    "                     x, s1, x1, s2, x2,\n",
    "                     dl_w1, dl_db1, dl_dw2, dl_db2)\n",
    "    \n",
    "        #update rule\n",
    "        w1 = w1 - step * dl_dw1\n",
    "        b1 = b1 - step * dl_db1\n",
    "        w2 = w2 - step * dl_dw2\n",
    "        w1 = w1 - step * dl_db2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

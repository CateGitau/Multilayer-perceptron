{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a multi-layer perceptron with one hidden layer from scratch and test it on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigma(x):\n",
    "    return 1 - sigma(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(v, t):\n",
    "    return (v-t).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss(v, t):\n",
    "    return 2*(v-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "torch.Size([1000, 784])\n"
     ]
    }
   ],
   "source": [
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "train_input, train_target, test_input,test_target = prologue.load_data(one_hot_labels = True,\n",
    "                                                                      normalize = True)\n",
    "\n",
    "train_target = train_target * 0.9\n",
    "test_target  = test_target * 0.9\n",
    "print(train_input.shape)\n",
    "\n",
    "nb_hidden = 50\n",
    "epsilon = 1e-6\n",
    "nb_classes = train_target.size(1)\n",
    "nb_train_samples = train_input.size(0)\n",
    "learning_rate = 0.1\n",
    "step = learning_rate/nb_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.empty(nb_hidden, train_input.size(1)).normal_(0, epsilon)\n",
    "b1 = torch.empty(nb_hidden, train_input.size(0)).normal_(0, epsilon)\n",
    "w2 = torch.empty(nb_classes, nb_hidden).normal_(0, epsilon)\n",
    "b2 = torch.empty(nb_classes, train_input.size(0)).normal_(0, epsilon)\n",
    "\n",
    "\n",
    "dl_dw1 = torch.empty(w1.size())\n",
    "dl_db1 = torch.empty(b1.size())\n",
    "dl_dw2 = torch.empty(w2.size())\n",
    "dl_db2 = torch.empty(b2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x\n",
    "    s1 = torch.add(torch.mm(w1, torch.transpose(x0, 0, 1)), b1)\n",
    "    x1 = sigma(s1)\n",
    "    s2 = torch.add(torch.mm(w2,x1), b2)\n",
    "    x2 = sigma(s1)\n",
    "    \n",
    "    return x0, s1, x1, s2, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b1.shape\n",
    "#s1 = torch.add(torch.mm(w1, torch.transpose(x, 0, 1)), b1)\n",
    "#x1 = sigma(s1)\n",
    "\n",
    "#x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5593e-05,  1.0198e-05, -2.3631e-06,  ...,  1.6863e-06,\n",
       "          -1.6162e-05, -9.4213e-06],\n",
       "         [-3.7875e-06, -3.2296e-05,  4.7850e-05,  ..., -4.6781e-06,\n",
       "          -4.6001e-06, -1.1158e-07],\n",
       "         [ 4.6948e-05,  7.5915e-05,  2.7812e-05,  ...,  2.7371e-05,\n",
       "           7.3137e-05,  1.9534e-05],\n",
       "         ...,\n",
       "         [-1.3455e-06,  4.8133e-05,  1.0704e-05,  ...,  2.6426e-05,\n",
       "           1.2760e-05, -1.0481e-05],\n",
       "         [-3.2370e-06,  1.0217e-05, -8.3648e-06,  ...,  1.4750e-05,\n",
       "          -3.8282e-05, -2.4374e-05],\n",
       "         [-1.8823e-05, -9.4006e-06,  3.9139e-05,  ...,  5.9774e-06,\n",
       "          -3.2895e-05, -4.1299e-05]]),\n",
       " tensor([[-1.5593e-05,  1.0198e-05, -2.3631e-06,  ...,  1.6863e-06,\n",
       "          -1.6162e-05, -9.4213e-06],\n",
       "         [-3.7875e-06, -3.2296e-05,  4.7850e-05,  ..., -4.6781e-06,\n",
       "          -4.6001e-06, -1.1158e-07],\n",
       "         [ 4.6948e-05,  7.5915e-05,  2.7812e-05,  ...,  2.7371e-05,\n",
       "           7.3137e-05,  1.9534e-05],\n",
       "         ...,\n",
       "         [-1.3455e-06,  4.8133e-05,  1.0704e-05,  ...,  2.6426e-05,\n",
       "           1.2760e-05, -1.0481e-05],\n",
       "         [-3.2370e-06,  1.0217e-05, -8.3648e-06,  ...,  1.4750e-05,\n",
       "          -3.8282e-05, -2.4374e-05],\n",
       "         [-1.8823e-05, -9.4006e-06,  3.9139e-05,  ...,  5.9774e-06,\n",
       "          -3.2895e-05, -4.1299e-05]]),\n",
       " tensor([[-1.8431e-06, -1.0317e-06,  2.4151e-07,  ...,  1.0944e-06,\n",
       "          -1.2781e-06,  5.4195e-07],\n",
       "         [ 2.0126e-06,  2.6788e-06,  4.3181e-07,  ...,  1.2095e-06,\n",
       "           1.2256e-06, -1.3566e-07],\n",
       "         [-5.1741e-07,  1.0916e-06, -6.8374e-07,  ..., -7.2152e-07,\n",
       "          -1.1232e-06,  5.1104e-07],\n",
       "         ...,\n",
       "         [ 2.4029e-07,  1.4234e-06,  1.4126e-06,  ..., -7.9391e-07,\n",
       "           7.6463e-07,  2.2841e-07],\n",
       "         [-9.7168e-07, -9.2956e-08, -4.7864e-07,  ..., -2.3170e-07,\n",
       "           1.1457e-06,  6.7951e-07],\n",
       "         [ 1.1335e-07, -2.8379e-07, -5.0871e-07,  ...,  1.8021e-07,\n",
       "          -7.0508e-07,  2.7973e-07]]),\n",
       " tensor([[-1.5593e-05,  1.0198e-05, -2.3631e-06,  ...,  1.6863e-06,\n",
       "          -1.6162e-05, -9.4213e-06],\n",
       "         [-3.7875e-06, -3.2296e-05,  4.7850e-05,  ..., -4.6781e-06,\n",
       "          -4.6001e-06, -1.1158e-07],\n",
       "         [ 4.6948e-05,  7.5915e-05,  2.7812e-05,  ...,  2.7371e-05,\n",
       "           7.3137e-05,  1.9534e-05],\n",
       "         ...,\n",
       "         [-1.3455e-06,  4.8133e-05,  1.0704e-05,  ...,  2.6426e-05,\n",
       "           1.2760e-05, -1.0481e-05],\n",
       "         [-3.2370e-06,  1.0217e-05, -8.3648e-06,  ...,  1.4750e-05,\n",
       "          -3.8282e-05, -2.4374e-05],\n",
       "         [-1.8823e-05, -9.4006e-06,  3.9139e-05,  ...,  5.9774e-06,\n",
       "          -3.2895e-05, -4.1299e-05]]),\n",
       " tensor([[-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203],\n",
       "         [-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203],\n",
       "         [-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203],\n",
       "         ...,\n",
       "         [-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203],\n",
       "         [-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203],\n",
       "         [-0.4203, -0.4203, -0.4203,  ..., -0.4203, -0.4203, -0.4203]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(w1, w2, b1, b2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                 dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    \n",
    "    dl_dx2 = loss(x2, t)\n",
    "    dl_ds2 = torch.mm(dl_dx2, dsigma)\n",
    "    dl_dx1 = torch.mm(dl_s2, w2)\n",
    "    dl_ds1 = torch.mm(dl_dx1, dsigma(s1))\n",
    "    \n",
    "    dl_dw2 = torch.mm(dl_ds2, x1)\n",
    "    dl_db2 = torch.mm(dl_ds2, 1)\n",
    "    dl_db1 = torch.mm(dl_ds1, 1)\n",
    "    dl_dw1 = torch.mm(dl_ds1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-16fe633ba0b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                      \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                      dl_dw1, dl_db1, dl_dw2, dl_db2)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#update rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7b81daef47a0>\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(w1, b1, w2, b2, t, x, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2)\u001b[0m\n\u001b[1;32m      4\u001b[0m                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdl_dx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdl_ds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_dx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdl_dx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_s2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a1cbaf40a6b3>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(v, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for k in range(1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performing 1,000 gradient steps with a step size equal to 0.1 divided\n",
    "    by the number of training samples(variable--steps)\n",
    "    First reset the tensors to zero for summing up the gradients and doing\n",
    "    a forward and backward pass for each training example\n",
    "    \"\"\"\n",
    "    dl_dw1 = torch.zeros(dl_dw1.shape)\n",
    "    dl_db1 = torch.zeros(dl_db1.shape)\n",
    "    dl_dw2 = torch.zeros(dl_dw2.shape)\n",
    "    dl_db2 = torch.zeros(dl_db2.shape)\n",
    "    \n",
    "    for n in range(nb_train_samples):\n",
    "        #forward prop\n",
    "        x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, x)\n",
    "    \n",
    "        #backward prop\n",
    "        backward_pass(w1, b1, w2, b2,\n",
    "                     train_target[n],\n",
    "                     x, s1, x1, s2, x2,\n",
    "                     dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "    \n",
    "        #update rule\n",
    "        w1 = w1 - step * dl_dw1\n",
    "        b1 = b1 - step * dl_db1\n",
    "        w2 = w2 - step * dl_dw2\n",
    "        w1 = w1 - step * dl_db2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (50) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-079fa9460794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b81541ac9ca3>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(w1, b1, w2, b2, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (50) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x, s1, x1, s2, x2 = forward_pass(w1, w2, b1, b2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
